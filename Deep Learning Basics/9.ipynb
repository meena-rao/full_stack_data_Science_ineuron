{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9487340",
   "metadata": {},
   "source": [
    "### FSDS DL assignment 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbadb751",
   "metadata": {},
   "source": [
    "#### 1.\tWhat are the main tasks that autoencoders are used for?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8947212a",
   "metadata": {},
   "source": [
    "Autoencoders are used for various tasks such as data compression, data denoising, anomaly detection, feature extraction, and data generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aae809",
   "metadata": {},
   "source": [
    "#### 2.\tSuppose you want to train a classifier, and you have plenty of unlabeled training data but only a few thousand labeled instances. How can autoencoders help? How would you proceed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb768ca",
   "metadata": {},
   "source": [
    "Autoencoders can help in this scenario by pretraining the neural network on the unlabeled data using an unsupervised approach. This pretraining can improve the performance of the classifier when fine-tuned with the labeled data. To proceed, you can first train an autoencoder on the unlabeled data, and then use the encoder part of the autoencoder as a feature extractor for the labeled data. The extracted features can then be fed to a classifier for fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9691d36b",
   "metadata": {},
   "source": [
    "#### 3.\tIf an autoencoder perfectly reconstructs the inputs, is it necessarily a good auto#encoder? How can you evaluate the performance of an autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c14d7",
   "metadata": {},
   "source": [
    "No, perfect reconstruction does not necessarily mean a good autoencoder. The performance of an autoencoder can be evaluated by measuring the reconstruction error or the difference between the input and the output. However, this alone is not enough to evaluate the quality of the learned representation. Other evaluation metrics, such as the ability to generalize to new data, can also be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d15ea",
   "metadata": {},
   "source": [
    "#### 4.\tWhat are undercomplete and overcomplete autoencoders? What is the main risk of an excessively undercomplete autoencoder? What about the main risk of an overcomplete autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240f118",
   "metadata": {},
   "source": [
    "Undercomplete autoencoders have a bottleneck in the middle layer that compresses the input to a lower dimensional space. Overcomplete autoencoders have more units in the bottleneck layer than the input layer, which can lead to the model learning an identity mapping. The main risk of an excessively undercomplete autoencoder is losing important information during compression. The main risk of an overcomplete autoencoder is overfitting to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a563a",
   "metadata": {},
   "source": [
    "#### 5.\tHow do you tie weights in a stacked autoencoder? What is the point of doing so?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae77a07",
   "metadata": {},
   "source": [
    "Tying weights in a stacked autoencoder involves sharing the weights between the encoder and decoder of each layer. The point of doing so is to reduce the number of parameters in the model and improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce86b649",
   "metadata": {},
   "source": [
    "#### 6.\tWhat is a generative model? Can you name a type of generative autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15278f2a",
   "metadata": {},
   "source": [
    "A generative model is a type of model that learns to generate new data similar to the training data. A type of generative autoencoder is the Variational Autoencoder (VAE), which learns a probability distribution over the latent space and uses it to generate new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300759a9",
   "metadata": {},
   "source": [
    "#### 7.\tWhat is a GAN? Can you name a few tasks where GANs can shine?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0145ada",
   "metadata": {},
   "source": [
    "GAN stands for Generative Adversarial Network, which is a type of generative model that learns to generate new data by pitting a generator network against a discriminator network. GANs can shine in tasks such as image and video generation, style transfer, and data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecbe53d",
   "metadata": {},
   "source": [
    "#### 8.\tWhat are the main difficulties when training GANs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17e424d",
   "metadata": {},
   "source": [
    "The main difficulties when training GANs include mode collapse, vanishing gradients, and instability during training. Mode collapse occurs when the generator learns to produce a limited set of outputs, while vanishing gradients can make it difficult to train the discriminator. Instability during training can also cause the generator and discriminator to become unbalanced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
