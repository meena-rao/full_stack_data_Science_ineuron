{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96460c13",
   "metadata": {},
   "source": [
    "## ML14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5821fd8",
   "metadata": {},
   "source": [
    "1. What is the concept of supervised learning? What is the significance of the name?\n",
    "2. In the hospital sector, offer an example of supervised learning.\n",
    "3. Give three supervised learning examples.\n",
    "\n",
    "4. In supervised learning, what are classification and regression?\n",
    "\n",
    "5. Give some popular classification algorithms as examples.\n",
    "\n",
    "6. Briefly describe the SVM model.\n",
    "\n",
    "7. In SVM, what is the cost of misclassification?\n",
    "\n",
    "8. In the SVM model, define Support Vectors.\n",
    "\n",
    "9. In the SVM model, define the kernel.\n",
    "\n",
    "10. What are the factors that influence SVM&#39;s effectiveness?\n",
    "\n",
    "11. What are the benefits of using the SVM model?\n",
    "\n",
    "12. What are the drawbacks of using the SVM model?\n",
    "\n",
    "13. Notes should be written on\n",
    "\n",
    "The kNN algorithm has a validation flaw.\n",
    "\n",
    " In the kNN algorithm, the k value is chosen.\n",
    "\n",
    " A decision tree with inductive bias\n",
    "\n",
    "14. What are some of the benefits of the kNN algorithm?\n",
    "\n",
    "15. What are some of the kNN algorithm&#39;s drawbacks?\n",
    "\n",
    "16. Explain the decision tree algorithm in a few words.\n",
    "\n",
    "17. What is the difference between a node and a leaf in a decision tree?\n",
    "\n",
    "18. What is a decision tree&#39;s entropy?\n",
    "\n",
    "19. In a decision tree, define knowledge gain.\n",
    "\n",
    "20. Choose three advantages of the decision tree approach and write them down.\n",
    "\n",
    "21. Make a list of three flaws in the decision tree process.\n",
    "\n",
    "22. Briefly describe the random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94bca6",
   "metadata": {},
   "source": [
    "1. Supervised learning is a type of machine learning in which an algorithm is trained on labeled data to learn the mapping between input data and output labels. The significance of the name \"supervised\" is that the algorithm is trained using labeled data, with the labels acting as a supervisor guiding the learning process.\n",
    "\n",
    "2. An example of supervised learning in the hospital sector could be predicting whether a patient has diabetes or not based on their medical history and other relevant factors.\n",
    "\n",
    "3. Three examples of supervised learning are image classification (identifying whether an image contains a dog or a cat), spam filtering (determining whether an email is spam or not), and stock price prediction (predicting the future stock price of a company).\n",
    "\n",
    "4. Classification and regression are two types of supervised learning problems. In classification, the goal is to predict a categorical label, while in regression, the goal is to predict a continuous output value.\n",
    "\n",
    "5. Popular classification algorithms include logistic regression, decision trees, random forests, k-nearest neighbors (kNN), and support vector machines (SVM).\n",
    "\n",
    "6. The SVM (Support Vector Machine) model is a type of supervised learning algorithm used for classification and regression. It works by finding the hyperplane that maximizes the margin between two classes in the feature space.\n",
    "\n",
    "7. In SVM, the cost of misclassification is a penalty for predicting the wrong class. It is typically set by the user as a hyperparameter and determines the balance between model complexity and accuracy.\n",
    "\n",
    "8. Support Vectors are the data points that lie closest to the decision boundary in the SVM model. They are the points that define the maximum margin hyperplane and are used to make predictions on new data points.\n",
    "\n",
    "9. In the SVM model, the kernel is a function that transforms the input data into a higher-dimensional feature space where the decision boundary can be better separated.\n",
    "\n",
    "10. The factors that influence SVM's effectiveness include the choice of kernel function, the regularization parameter, the cost of misclassification, and the number of support vectors.\n",
    "\n",
    "11. The benefits of using the SVM model include its ability to handle high-dimensional data, its effectiveness in dealing with noisy data, and its robustness to overfitting.\n",
    "\n",
    "12. The drawbacks of using the SVM model include its sensitivity to the choice of kernel function, its inability to handle large datasets, and its difficulty in interpreting the results.\n",
    "\n",
    "13. The kNN algorithm has a validation flaw where the performance can vary significantly based on the choice of k and the dataset size.\n",
    "\n",
    " In the kNN algorithm, the k value is chosen based on the dataset size and the model's complexity.\n",
    "\n",
    " A decision tree with inductive bias is a type of decision tree that is biased towards certain solutions based on prior knowledge or assumptions.\n",
    "\n",
    "14. Some benefits of the kNN algorithm include its simplicity, its ability to handle non-linear data, and its effectiveness in low-dimensional spaces.\n",
    "\n",
    "15. Some drawbacks of the kNN algorithm include its sensitivity to the choice of k, its inability to handle high-dimensional data, and its poor performance on imbalanced datasets.\n",
    "\n",
    "16. The decision tree algorithm is a type of supervised learning algorithm that builds a tree-like model of decisions and their possible consequences based on input data.\n",
    "\n",
    "17. In a decision tree, a node represents a decision based on a feature or attribute, while a leaf represents a final classification or prediction based on the decisions made at the nodes.\n",
    "\n",
    "18. Entropy in a decision tree refers to the measure of impurity or disorder in a set of data. It is used to calculate the information gain at each node and determine the best attribute to split the data.\n",
    "\n",
    "19. In a decision tree, knowledge gain refers to the difference in entropy before and after splitting the data based on a particular attribute. It is used to select the attribute that maximizes the information gain and improves the accuracy of the decision tree.\n",
    "\n",
    "20. Three advantages of the decision tree approach are its simplicity and interpretability, its ability to handle both categorical and continuous data, and its effectiveness in handling missing values and noisy data.\n",
    "\n",
    "21. Three flaws in the decision tree process are overfitting, bias towards certain features, and instability due to small changes in the training data.\n",
    "\n",
    "22. The random forest model is an ensemble learning method that combines multiple decision trees to improve the accuracy and robustness of the model. It works by randomly selecting subsets of features and data samples for each tree, and then aggregating the results to make a final prediction. Random forests are effective in handling high-dimensional data, noisy data, and imbalanced datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
